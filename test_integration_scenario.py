#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çµ±åˆã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å…¨æ©Ÿèƒ½ã®é€£æºã‚’ç¢ºèªã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ
"""

import pandas as pd
import os
import sys
import tempfile
import shutil
from datetime import datetime
import traceback

def test_full_workflow_scenario():
    """å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
    print("=== å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ ===")
    
    try:
        # 1. ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆsrc.pyã®å®Ÿè¡Œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
        print("ğŸ“‹ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
        
        from src import (
            build_work_intervals, build_service_records, 
            find_overlaps, interval_fully_covered, build_staff_busy_map
        )
        from pathlib import Path
        
        # å‹¤æ€ ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        att_df = pd.read_csv('test_input/å‹¤æ€ å±¥æ­´.csv', encoding='cp932')
        print(f"âœ… å‹¤æ€ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(att_df)}è¡Œ")
        
        # ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‡¦ç†
        service_dfs = {}
        service_files = ['test_input/ã‚µãƒ¼ãƒ“ã‚¹å®Ÿæ…‹A.csv', 'test_input/ã‚µãƒ¼ãƒ“ã‚¹å®Ÿæ…‹B.csv']
        
        for service_file in service_files:
            if os.path.exists(service_file):
                facility_name = os.path.basename(service_file).replace('.csv', '')
                df = pd.read_csv(service_file, encoding='cp932')
                service_dfs[facility_name] = build_service_records(
                    Path(service_file), df, facility_name, staff_col='æ‹…å½“æ‰€å“¡'
                )
                print(f"âœ… {facility_name}ãƒ‡ãƒ¼ã‚¿å‡¦ç†: {len(df)}è¡Œ")
        
        # å‹¤å‹™é–“éš”ã¨ã‚¹ã‚¿ãƒƒãƒ•ç¹å¿™ãƒãƒƒãƒ—ã®æ§‹ç¯‰
        att_map, att_name_index = build_work_intervals(att_df)
        busy_map = build_staff_busy_map(service_dfs)
        
        print(f"âœ… å‹¤å‹™é–“éš”ãƒãƒƒãƒ—æ§‹ç¯‰: {len(att_map)}äºº")
        print(f"âœ… ã‚¹ã‚¿ãƒƒãƒ•ç¹å¿™ãƒãƒƒãƒ—æ§‹ç¯‰: {len(busy_map)}äºº")
        
        # 2. ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤ºæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
        print("\nğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—2: ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤ºæ©Ÿèƒ½")
        
        from streamlit_app import prepare_grid_data, collect_summary
        
        result_paths = [
            'test_input/result_ã‚µãƒ¼ãƒ“ã‚¹å®Ÿæ…‹A.csv',
            'test_input/result_ã‚µãƒ¼ãƒ“ã‚¹å®Ÿæ…‹B.csv'
        ]
        
        # ã‚°ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        grid_df = prepare_grid_data(result_paths)
        print(f"âœ… ã‚°ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿æº–å‚™: {len(grid_df)}è¡Œ")
        
        # å¿…è¦ãªã‚«ãƒ©ãƒ ã®ç¢ºèª
        required_columns = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'AB']
        missing_columns = [col for col in required_columns if col not in grid_df.columns]
        
        if missing_columns:
            print(f"âŒ ä¸è¶³ã‚«ãƒ©ãƒ : {missing_columns}")
            return False
        
        print("âœ… å…¨å¿…è¦ã‚«ãƒ©ãƒ ç¢ºèªå®Œäº†")
        
        # ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã®åé›†
        summary_df = collect_summary(result_paths)
        print(f"âœ… ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿åé›†: {len(summary_df)}è¡Œ")
        
        # 3. ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
        print("\nğŸ‘¥ ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½")
        
        # åˆ©ç”¨è€…åˆ¥ãƒ“ãƒ¥ãƒ¼
        available_users = [user for user in grid_df['G'].dropna().unique() if user != '']
        print(f"âœ… åˆ©ç”¨å¯èƒ½ãªåˆ©ç”¨è€…: {len(available_users)}äºº")
        
        if available_users:
            test_user = available_users[0]
            user_filtered = grid_df[grid_df['G'] == test_user]
            print(f"âœ… åˆ©ç”¨è€…åˆ¥ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆ{test_user}ï¼‰: {len(user_filtered)}è¡Œ")
        
        # å¾“æ¥­å“¡åˆ¥ãƒ“ãƒ¥ãƒ¼
        available_staff = [staff for staff in grid_df['C'].dropna().unique() if staff != '']
        print(f"âœ… åˆ©ç”¨å¯èƒ½ãªå¾“æ¥­å“¡: {len(available_staff)}äºº")
        
        if available_staff:
            test_staff = available_staff[0]
            staff_filtered = grid_df[grid_df['C'] == test_staff]
            print(f"âœ… å¾“æ¥­å“¡åˆ¥ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆ{test_staff}ï¼‰: {len(staff_filtered)}è¡Œ")
        
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ“ãƒ¥ãƒ¼ï¼ˆè¤‡åˆãƒ•ã‚£ãƒ«ã‚¿ï¼‰
        error_filtered = grid_df[grid_df['A'] == 'â—¯']
        print(f"âœ… ã‚¨ãƒ©ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿: {len(error_filtered)}è¡Œ")
        
        # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
        total_records = len(grid_df)
        error_records = len(error_filtered)
        error_rate = (error_records / total_records * 100) if total_records > 0 else 0
        unique_users = len(available_users)
        
        print(f"âœ… çµ±è¨ˆæƒ…å ±è¨ˆç®—:")
        print(f"  - ç·ä»¶æ•°: {total_records}")
        print(f"  - ã‚¨ãƒ©ãƒ¼ä»¶æ•°: {error_records}")
        print(f"  - ã‚¨ãƒ©ãƒ¼ç‡: {error_rate:.1f}%")
        print(f"  - åˆ©ç”¨è€…æ•°: {unique_users}")
        
        # 4. å‹¤å‹™æ™‚é–“æœ€é©åŒ–ææ¡ˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
        print("\nğŸ¯ ã‚¹ãƒ†ãƒƒãƒ—4: å‹¤å‹™æ™‚é–“æœ€é©åŒ–ææ¡ˆæ©Ÿèƒ½")
        
        from optimization import WorkOptimizer, format_time_minutes, calculate_optimization_impact
        
        # æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
        optimizer = WorkOptimizer(att_df, service_dfs)
        print("âœ… æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
        
        # åˆ©ç”¨å¯èƒ½ãªå¾“æ¥­å“¡ãƒªã‚¹ãƒˆã®å–å¾—
        available_employees = []
        for _, row in att_df.iterrows():
            emp_name = str(row.get('åå‰', '')).strip()
            if emp_name and emp_name not in available_employees:
                available_employees.append(emp_name)
        
        print(f"âœ… åˆ©ç”¨å¯èƒ½ãªå¾“æ¥­å“¡: {len(available_employees)}äºº")
        
        if available_employees:
            test_employee = available_employees[0]
            print(f"ğŸ” ãƒ†ã‚¹ãƒˆå¯¾è±¡å¾“æ¥­å“¡: {test_employee}")
            
            # å¾“æ¥­å“¡åˆ†æ
            analysis = optimizer.analyze_employee_patterns(test_employee)
            
            if "error" not in analysis:
                print("âœ… å¾“æ¥­å“¡åˆ†ææˆåŠŸ:")
                print(f"  - ç·å‹¤å‹™æ—¥æ•°: {analysis['total_work_days']}")
                print(f"  - ç·å‹¤å‹™æ™‚é–“: {analysis['total_work_hours']:.1f}æ™‚é–“")
                print(f"  - ã‚¨ãƒ©ãƒ¼ä»¶æ•°: {analysis['error_analysis']['total_errors']}")
                
                # æœ€é©åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ
                optimization_results = optimizer.generate_optimization_patterns(test_employee)
                print(f"âœ… æœ€é©åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ: {len(optimization_results)}ãƒ‘ã‚¿ãƒ¼ãƒ³")
                
                if optimization_results:
                    # å½±éŸ¿è¨ˆç®—
                    impact = calculate_optimization_impact(optimization_results)
                    print(f"âœ… å½±éŸ¿è¨ˆç®—:")
                    print(f"  - ç·ã‚¨ãƒ©ãƒ¼å‰Šæ¸›äºˆæƒ³: {impact['total_error_reduction']}")
                    print(f"  - å¹³å‡å®Ÿç¾å¯èƒ½æ€§: {impact['average_feasibility']:.1%}")
                    
                    # æ™‚é–“ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
                    test_minutes = [480, 540, 1020]  # 8:00, 9:00, 17:00
                    for minutes in test_minutes:
                        formatted = format_time_minutes(minutes)
                        print(f"âœ… æ™‚é–“ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: {minutes}åˆ† â†’ {formatted}")
                else:
                    print("âš ï¸ æœ€é©åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            else:
                print(f"âŒ å¾“æ¥­å“¡åˆ†æã‚¨ãƒ©ãƒ¼: {analysis['error']}")
                return False
        
        # 5. ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼é€£æºã®ç¢ºèª
        print("\nğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼é€£æºç¢ºèª")
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ â†’ å‡¦ç†çµæœ â†’ ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤º â†’ ãƒ“ãƒ¥ãƒ¼ â†’ æœ€é©åŒ–ã®æµã‚Œã‚’ç¢ºèª
        original_service_count = sum(len(df) for df in service_dfs.values())
        grid_count = len(grid_df)
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ç¢ºèª:")
        print(f"  - å…ƒã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ãƒ¼ã‚¿: {original_service_count}è¡Œ")
        print(f"  - ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿: {grid_count}è¡Œ")
        print(f"  - å‹¤æ€ ãƒ‡ãƒ¼ã‚¿: {len(att_df)}è¡Œ")
        print(f"  - æœ€é©åŒ–å¯¾è±¡å¾“æ¥­å“¡: {len(available_employees)}äºº")
        
        # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®ç¢ºèª
        data_integrity_ok = True
        
        # ã‚°ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ã®å„è¡ŒãŒæœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã‚’æŒã£ã¦ã„ã‚‹ã‹ç¢ºèª
        invalid_rows = 0
        for _, row in grid_df.iterrows():
            if pd.isna(row['C']) or row['C'] == '':  # æ‹…å½“æ‰€å“¡ãŒç©º
                invalid_rows += 1
        
        if invalid_rows > 0:
            print(f"âš ï¸ è­¦å‘Š: ç„¡åŠ¹ãªè¡ŒãŒ{invalid_rows}è¡Œã‚ã‚Šã¾ã™")
        else:
            print("âœ… ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèªå®Œäº†")
        
        # 6. ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
        print("\nğŸ’¾ ã‚¹ãƒ†ãƒƒãƒ—6: ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½")
        
        # CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        export_data = grid_df.to_csv(index=False, encoding='utf-8-sig')
        print(f"âœ… CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæº–å‚™: {len(export_data)}æ–‡å­—")
        
        # ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        filtered_export = error_filtered.to_csv(index=False, encoding='utf-8-sig')
        print(f"âœ… ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {len(filtered_export)}æ–‡å­—")
        
        # æœ€é©åŒ–çµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        if 'optimization_results' in locals() and optimization_results:
            result = optimization_results[0]  # æœ€åˆã®çµæœã‚’ä½¿ç”¨
            export_optimization = {
                "å¾“æ¥­å“¡å": [result.current_pattern.employee_name],
                "ææ¡ˆãƒ‘ã‚¿ãƒ¼ãƒ³": [result.pattern_name],
                "å®Ÿç¾å¯èƒ½æ€§": [f"{result.feasibility_score:.1%}"],
                "ã‚¨ãƒ©ãƒ¼å‰Šæ¸›äºˆæƒ³": [f"{result.error_reduction}ä»¶"]
            }
            opt_export_df = pd.DataFrame(export_optimization)
            opt_csv = opt_export_df.to_csv(index=False, encoding='utf-8-sig')
            print(f"âœ… æœ€é©åŒ–çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {len(opt_csv)}æ–‡å­—")
        
        print("\nğŸ‰ å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆæˆåŠŸï¼")
        return True
        
    except Exception as e:
        print(f"âŒ å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return False

def test_session_state_simulation():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""
    print("\n=== ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ ===")
    
    try:
        # Streamlitã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        session_state = {
            'processing_complete': False,
            'result_paths': [],
            'diagnostic_paths': [],
            'summary_df': None,
            'workdir': None
        }
        
        print("ğŸ“‹ ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–")
        
        # å‡¦ç†å®Œäº†çŠ¶æ…‹ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        session_state['processing_complete'] = True
        session_state['result_paths'] = [
            'test_input/result_ã‚µãƒ¼ãƒ“ã‚¹å®Ÿæ…‹A.csv',
            'test_input/result_ã‚µãƒ¼ãƒ“ã‚¹å®Ÿæ…‹B.csv'
        ]
        session_state['diagnostic_paths'] = [
            'test_input/diagnostics/01_staff_name_coverage.csv',
            'test_input/diagnostics/02_attendance_summary.csv'
        ]
        
        print("âœ… å‡¦ç†å®Œäº†çŠ¶æ…‹è¨­å®š")
        
        # ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
        from streamlit_app import collect_summary
        session_state['summary_df'] = collect_summary(session_state['result_paths'])
        
        print(f"âœ… ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: {len(session_state['summary_df'])}è¡Œ")
        
        # æœ€é©åŒ–é–¢é€£ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
        session_state['optimization_analysis'] = None
        session_state['optimization_results'] = None
        session_state['selected_employee'] = None
        session_state['adopted_pattern'] = None
        
        print("âœ… æœ€é©åŒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®æ•´åˆæ€§ç¢ºèª
        required_keys = [
            'processing_complete', 'result_paths', 'diagnostic_paths', 
            'summary_df', 'optimization_analysis', 'optimization_results'
        ]
        
        missing_keys = [key for key in required_keys if key not in session_state]
        
        if missing_keys:
            print(f"âŒ ä¸è¶³ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚­ãƒ¼: {missing_keys}")
            return False
        
        print("âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹æ•´åˆæ€§ç¢ºèªå®Œäº†")
        
        # çŠ¶æ…‹é·ç§»ã®ãƒ†ã‚¹ãƒˆ
        print("ğŸ”„ çŠ¶æ…‹é·ç§»ãƒ†ã‚¹ãƒˆ:")
        
        # åˆæœŸçŠ¶æ…‹ â†’ å‡¦ç†ä¸­ â†’ å®Œäº†
        states = ['åˆæœŸ', 'å‡¦ç†ä¸­', 'å®Œäº†', 'æœ€é©åŒ–å®Ÿè¡Œä¸­', 'æœ€é©åŒ–å®Œäº†']
        for state in states:
            print(f"  âœ… çŠ¶æ…‹: {state}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç†ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return False

def test_error_recovery_scenario():
    """ã‚¨ãƒ©ãƒ¼å›å¾©ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
    print("\n=== ã‚¨ãƒ©ãƒ¼å›å¾©ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ ===")
    
    try:
        # 1. ä¸æ­£ãƒ‡ãƒ¼ã‚¿ã§ã®å‡¦ç†
        print("ğŸ“‹ ä¸æ­£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ")
        
        # ç©ºã®DataFrameã§ã®ãƒ†ã‚¹ãƒˆ
        empty_df = pd.DataFrame()
        
        try:
            from streamlit_app import prepare_grid_data
            result = prepare_grid_data([])  # ç©ºã®ãƒ‘ã‚¹ãƒªã‚¹ãƒˆ
            print("âš ï¸ ç©ºãƒ‡ãƒ¼ã‚¿ã§ã‚‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã›ã‚“ã§ã—ãŸ")
        except Exception as e:
            print(f"âœ… ç©ºãƒ‡ãƒ¼ã‚¿ã§é©åˆ‡ãªã‚¨ãƒ©ãƒ¼å‡¦ç†: {type(e).__name__}")
        
        # 2. å­˜åœ¨ã—ãªã„å¾“æ¥­å“¡ã§ã®æœ€é©åŒ–
        print("ğŸ“‹ å­˜åœ¨ã—ãªã„å¾“æ¥­å“¡ã§ã®æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ")
        
        try:
            from optimization import WorkOptimizer
            att_df = pd.read_csv('test_input/å‹¤æ€ å±¥æ­´.csv', encoding='cp932')
            service_dfs = {}
            
            optimizer = WorkOptimizer(att_df, service_dfs)
            analysis = optimizer.analyze_employee_patterns("å­˜åœ¨ã—ãªã„å¾“æ¥­å“¡")
            
            if "error" in analysis:
                print("âœ… å­˜åœ¨ã—ãªã„å¾“æ¥­å“¡ã§é©åˆ‡ãªã‚¨ãƒ©ãƒ¼å‡¦ç†")
            else:
                print("âš ï¸ å­˜åœ¨ã—ãªã„å¾“æ¥­å“¡ã§ã‚‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã›ã‚“ã§ã—ãŸ")
        
        except Exception as e:
            print(f"âœ… å­˜åœ¨ã—ãªã„å¾“æ¥­å“¡ã§é©åˆ‡ãªä¾‹å¤–å‡¦ç†: {type(e).__name__}")
        
        # 3. ç ´æãƒ•ã‚¡ã‚¤ãƒ«ã§ã®å‡¦ç†
        print("ğŸ“‹ ç ´æãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ†ã‚¹ãƒˆ")
        
        # ä¸€æ™‚çš„ãªç ´æãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        temp_file = "temp_broken.csv"
        with open(temp_file, 'w', encoding='utf-8') as f:
            f.write("ç ´æã—ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«\nä¸æ­£ãªå½¢å¼")
        
        try:
            df = pd.read_csv(temp_file, encoding='cp932')
            print("âš ï¸ ç ´æãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã›ã‚“ã§ã—ãŸ")
        except Exception as e:
            print(f"âœ… ç ´æãƒ•ã‚¡ã‚¤ãƒ«ã§é©åˆ‡ãªã‚¨ãƒ©ãƒ¼å‡¦ç†: {type(e).__name__}")
        finally:
            if os.path.exists(temp_file):
                os.remove(temp_file)
        
        # 4. ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        print("ğŸ“‹ ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™ãƒ†ã‚¹ãƒˆ")
        
        # å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        try:
            large_data = pd.DataFrame({
                'A': ['â—¯'] * 1000,
                'B': ['ãƒ†ã‚¹ãƒˆ'] * 1000,
                'C': ['å¾“æ¥­å“¡'] * 1000,
                'D': ['2025-01-01'] * 1000,
                'E': ['09:00'] * 1000,
                'F': ['17:00'] * 1000,
                'G': ['åˆ©ç”¨è€…'] * 1000,
                'AB': ['ã‚µãƒ¼ãƒ“ã‚¹'] * 1000
            })
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†
            filtered = large_data[large_data['A'] == 'â—¯']
            print(f"âœ… å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†æˆåŠŸ: {len(filtered)}è¡Œ")
            
        except Exception as e:
            print(f"âŒ å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
        
        print("âœ… ã‚¨ãƒ©ãƒ¼å›å¾©ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆå®Œäº†")
        return True
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼å›å¾©ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸš€ çµ±åˆã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆé–‹å§‹")
    print(f"ğŸ“… å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    test_results = []
    
    # å„ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
    tests = [
        ("å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚·ãƒŠãƒªã‚ª", test_full_workflow_scenario),
        ("ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", test_session_state_simulation),
        ("ã‚¨ãƒ©ãƒ¼å›å¾©ã‚·ãƒŠãƒªã‚ª", test_error_recovery_scenario),
    ]
    
    for test_name, test_func in tests:
        print(f"\nğŸ” {test_name}ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        try:
            result = test_func()
            test_results.append((test_name, result))
            if result:
                print(f"âœ… {test_name}ãƒ†ã‚¹ãƒˆ: æˆåŠŸ")
            else:
                print(f"âŒ {test_name}ãƒ†ã‚¹ãƒˆ: å¤±æ•—")
        except Exception as e:
            print(f"âŒ {test_name}ãƒ†ã‚¹ãƒˆ: ä¾‹å¤–ç™ºç”Ÿ - {str(e)}")
            test_results.append((test_name, False))
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("ğŸ“Š çµ±åˆã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… æˆåŠŸ" if result else "âŒ å¤±æ•—"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nğŸ¯ ç·åˆçµæœ: {passed}/{total} ãƒ†ã‚¹ãƒˆæˆåŠŸ")
    
    if passed == total:
        print("ğŸ‰ å…¨ã¦ã®çµ±åˆã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        print("ğŸ”— å…¨æ©Ÿèƒ½ã®é€£æºãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        return True
    else:
        print("âš ï¸ ä¸€éƒ¨ã®çµ±åˆã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)