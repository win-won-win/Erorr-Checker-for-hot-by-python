#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å¤§é‡ãƒ‡ãƒ¼ã‚¿ã§ã®å‹•ä½œç¢ºèªã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®š
"""

import pandas as pd
import time
import psutil
import os
import sys
from datetime import datetime
import traceback

def get_memory_usage():
    """ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—ï¼ˆMBï¼‰"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024

def test_large_data_performance():
    """å¤§é‡ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
    print("=== å¤§é‡ãƒ‡ãƒ¼ã‚¿ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ ===")
    
    try:
        from streamlit_app import prepare_grid_data, collect_summary
        
        # æ—¢å­˜ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        result_paths = [
            'test_input/result_ã‚µãƒ¼ãƒ“ã‚¹å®Ÿæ…‹A.csv',
            'test_input/result_ã‚µãƒ¼ãƒ“ã‚¹å®Ÿæ…‹B.csv'
        ]
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®šé–‹å§‹
        initial_memory = get_memory_usage()
        print(f"ğŸ“Š åˆæœŸãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {initial_memory:.2f} MB")
        
        # ã‚°ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿æº–å‚™ã®å‡¦ç†æ™‚é–“æ¸¬å®š
        start_time = time.time()
        grid_df = prepare_grid_data(result_paths)
        grid_time = time.time() - start_time
        
        grid_memory = get_memory_usage()
        print(f"âœ… ã‚°ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {grid_time:.3f}ç§’")
        print(f"ğŸ“Š ã‚°ãƒªãƒƒãƒ‰å‡¦ç†å¾Œãƒ¡ãƒ¢ãƒª: {grid_memory:.2f} MB (+{grid_memory-initial_memory:.2f} MB)")
        print(f"ğŸ“ˆ å‡¦ç†ãƒ‡ãƒ¼ã‚¿é‡: {len(grid_df)}è¡Œ")
        
        # ã‚µãƒãƒªãƒ¼åé›†ã®å‡¦ç†æ™‚é–“æ¸¬å®š
        start_time = time.time()
        summary_df = collect_summary(result_paths)
        summary_time = time.time() - start_time
        
        summary_memory = get_memory_usage()
        print(f"âœ… ã‚µãƒãƒªãƒ¼åé›†å®Œäº†: {summary_time:.3f}ç§’")
        print(f"ğŸ“Š ã‚µãƒãƒªãƒ¼å‡¦ç†å¾Œãƒ¡ãƒ¢ãƒª: {summary_memory:.2f} MB")
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ€§èƒ½ãƒ†ã‚¹ãƒˆ
        start_time = time.time()
        
        # ã‚¨ãƒ©ãƒ¼ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
        error_filtered = grid_df[grid_df['A'] == 'â—¯']
        
        # ç‰¹å®šã®å¾“æ¥­å“¡ã§ãƒ•ã‚£ãƒ«ã‚¿
        if not grid_df['C'].empty:
            staff_filtered = grid_df[grid_df['C'] == grid_df['C'].iloc[0]]
        
        # æ—¥ä»˜ç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆç°¡ç•¥ç‰ˆï¼‰
        date_filtered = grid_df[grid_df['D'].notna()]
        
        filter_time = time.time() - start_time
        filter_memory = get_memory_usage()
        
        print(f"âœ… ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†å®Œäº†: {filter_time:.3f}ç§’")
        print(f"ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œãƒ¡ãƒ¢ãƒª: {filter_memory:.2f} MB")
        print(f"ğŸ“ˆ ãƒ•ã‚£ãƒ«ã‚¿çµæœ:")
        print(f"  - ã‚¨ãƒ©ãƒ¼ã®ã¿: {len(error_filtered)}è¡Œ")
        print(f"  - å¾“æ¥­å“¡ãƒ•ã‚£ãƒ«ã‚¿: {len(staff_filtered) if 'staff_filtered' in locals() else 0}è¡Œ")
        print(f"  - æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿: {len(date_filtered)}è¡Œ")
        
        # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®è©•ä¾¡
        total_memory_increase = filter_memory - initial_memory
        memory_per_row = total_memory_increase / len(grid_df) if len(grid_df) > 0 else 0
        
        print(f"ğŸ“Š ãƒ¡ãƒ¢ãƒªåŠ¹ç‡:")
        print(f"  - ç·ãƒ¡ãƒ¢ãƒªå¢—åŠ : {total_memory_increase:.2f} MB")
        print(f"  - è¡Œã‚ãŸã‚Šãƒ¡ãƒ¢ãƒª: {memory_per_row:.4f} MB/è¡Œ")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
        total_time = grid_time + summary_time + filter_time
        rows_per_second = len(grid_df) / total_time if total_time > 0 else 0
        
        print(f"âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡:")
        print(f"  - ç·å‡¦ç†æ™‚é–“: {total_time:.3f}ç§’")
        print(f"  - å‡¦ç†é€Ÿåº¦: {rows_per_second:.1f}è¡Œ/ç§’")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº–ã®è©•ä¾¡
        performance_ok = True
        if total_time > 5.0:  # 5ç§’ä»¥ä¸Šã¯é…ã„
            print("âš ï¸ è­¦å‘Š: å‡¦ç†æ™‚é–“ãŒ5ç§’ã‚’è¶…ãˆã¦ã„ã¾ã™")
            performance_ok = False
        
        if total_memory_increase > 100:  # 100MBä»¥ä¸Šã¯å¤šã„
            print("âš ï¸ è­¦å‘Š: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒ100MBã‚’è¶…ãˆã¦ã„ã¾ã™")
            performance_ok = False
        
        if performance_ok:
            print("âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº–ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã„ã¾ã™")
        
        return performance_ok
        
    except Exception as e:
        print(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return False

def test_optimization_performance():
    """æœ€é©åŒ–æ©Ÿèƒ½ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
    print("\n=== æœ€é©åŒ–æ©Ÿèƒ½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ ===")
    
    try:
        from optimization import WorkOptimizer
        from src import build_service_records
        from pathlib import Path
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®šé–‹å§‹
        initial_memory = get_memory_usage()
        print(f"ğŸ“Š åˆæœŸãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {initial_memory:.2f} MB")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æ™‚é–“æ¸¬å®š
        start_time = time.time()
        
        att_df = pd.read_csv('test_input/å‹¤æ€ å±¥æ­´.csv', encoding='cp932')
        
        service_dfs = {}
        service_files = ['test_input/ã‚µãƒ¼ãƒ“ã‚¹å®Ÿæ…‹A.csv', 'test_input/ã‚µãƒ¼ãƒ“ã‚¹å®Ÿæ…‹B.csv']
        
        for service_file in service_files:
            if os.path.exists(service_file):
                facility_name = os.path.basename(service_file).replace('.csv', '')
                df = pd.read_csv(service_file, encoding='cp932')
                service_dfs[facility_name] = build_service_records(
                    Path(service_file), df, facility_name, staff_col='æ‹…å½“æ‰€å“¡'
                )
        
        load_time = time.time() - start_time
        load_memory = get_memory_usage()
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {load_time:.3f}ç§’")
        print(f"ğŸ“Š èª­ã¿è¾¼ã¿å¾Œãƒ¡ãƒ¢ãƒª: {load_memory:.2f} MB (+{load_memory-initial_memory:.2f} MB)")
        
        # æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–æ™‚é–“æ¸¬å®š
        start_time = time.time()
        optimizer = WorkOptimizer(att_df, service_dfs)
        init_time = time.time() - start_time
        init_memory = get_memory_usage()
        
        print(f"âœ… æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†: {init_time:.3f}ç§’")
        print(f"ğŸ“Š åˆæœŸåŒ–å¾Œãƒ¡ãƒ¢ãƒª: {init_memory:.2f} MB (+{init_memory-load_memory:.2f} MB)")
        
        # å…¨å¾“æ¥­å“¡ã®åˆ†ææ™‚é–“æ¸¬å®š
        available_employees = []
        for _, row in att_df.iterrows():
            emp_name = str(row.get('åå‰', '')).strip()
            if emp_name and emp_name not in available_employees:
                available_employees.append(emp_name)
        
        total_analysis_time = 0
        total_optimization_time = 0
        successful_analyses = 0
        
        for employee in available_employees[:3]:  # æœ€åˆã®3äººã‚’ãƒ†ã‚¹ãƒˆ
            # åˆ†ææ™‚é–“æ¸¬å®š
            start_time = time.time()
            analysis = optimizer.analyze_employee_patterns(employee)
            analysis_time = time.time() - start_time
            
            if "error" not in analysis:
                successful_analyses += 1
                total_analysis_time += analysis_time
                
                # æœ€é©åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆæ™‚é–“æ¸¬å®š
                start_time = time.time()
                optimization_results = optimizer.generate_optimization_patterns(employee)
                optimization_time = time.time() - start_time
                total_optimization_time += optimization_time
                
                print(f"âœ… {employee}: åˆ†æ{analysis_time:.3f}ç§’, æœ€é©åŒ–{optimization_time:.3f}ç§’, ãƒ‘ã‚¿ãƒ¼ãƒ³{len(optimization_results)}å€‹")
            else:
                print(f"âš ï¸ {employee}: åˆ†æå¤±æ•— - {analysis.get('error', 'Unknown error')}")
        
        final_memory = get_memory_usage()
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        if successful_analyses > 0:
            avg_analysis_time = total_analysis_time / successful_analyses
            avg_optimization_time = total_optimization_time / successful_analyses
            
            print(f"ğŸ“Š æœ€é©åŒ–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ:")
            print(f"  - æˆåŠŸã—ãŸåˆ†æ: {successful_analyses}/{len(available_employees[:3])}")
            print(f"  - å¹³å‡åˆ†ææ™‚é–“: {avg_analysis_time:.3f}ç§’/äºº")
            print(f"  - å¹³å‡æœ€é©åŒ–æ™‚é–“: {avg_optimization_time:.3f}ç§’/äºº")
            print(f"  - ç·ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {final_memory:.2f} MB")
            print(f"  - ãƒ¡ãƒ¢ãƒªå¢—åŠ : {final_memory-initial_memory:.2f} MB")
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº–ã®è©•ä¾¡
            performance_ok = True
            if avg_analysis_time > 2.0:  # 2ç§’ä»¥ä¸Šã¯é…ã„
                print("âš ï¸ è­¦å‘Š: åˆ†ææ™‚é–“ãŒ2ç§’ã‚’è¶…ãˆã¦ã„ã¾ã™")
                performance_ok = False
            
            if avg_optimization_time > 3.0:  # 3ç§’ä»¥ä¸Šã¯é…ã„
                print("âš ï¸ è­¦å‘Š: æœ€é©åŒ–æ™‚é–“ãŒ3ç§’ã‚’è¶…ãˆã¦ã„ã¾ã™")
                performance_ok = False
            
            if final_memory - initial_memory > 50:  # 50MBä»¥ä¸Šã¯å¤šã„
                print("âš ï¸ è­¦å‘Š: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒ50MBã‚’è¶…ãˆã¦ã„ã¾ã™")
                performance_ok = False
            
            if performance_ok:
                print("âœ… æœ€é©åŒ–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº–ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã„ã¾ã™")
            
            return performance_ok
        else:
            print("âŒ æˆåŠŸã—ãŸåˆ†æãŒã‚ã‚Šã¾ã›ã‚“")
            return False
        
    except Exception as e:
        print(f"âŒ æœ€é©åŒ–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return False

def test_concurrent_operations():
    """ä¸¦è¡Œå‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""
    print("\n=== ä¸¦è¡Œå‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ ===")
    
    try:
        from streamlit_app import prepare_grid_data
        
        # è¤‡æ•°å›ã®å‡¦ç†ã‚’é€£ç¶šå®Ÿè¡Œã—ã¦ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’ãƒã‚§ãƒƒã‚¯
        initial_memory = get_memory_usage()
        print(f"ğŸ“Š åˆæœŸãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {initial_memory:.2f} MB")
        
        result_paths = [
            'test_input/result_ã‚µãƒ¼ãƒ“ã‚¹å®Ÿæ…‹A.csv',
            'test_input/result_ã‚µãƒ¼ãƒ“ã‚¹å®Ÿæ…‹B.csv'
        ]
        
        memory_readings = []
        processing_times = []
        
        for i in range(5):  # 5å›é€£ç¶šå®Ÿè¡Œ
            start_time = time.time()
            grid_df = prepare_grid_data(result_paths)
            processing_time = time.time() - start_time
            
            current_memory = get_memory_usage()
            memory_readings.append(current_memory)
            processing_times.append(processing_time)
            
            print(f"  å®Ÿè¡Œ{i+1}: {processing_time:.3f}ç§’, ãƒ¡ãƒ¢ãƒª{current_memory:.2f}MB")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ˜ç¤ºçš„ã«å‰Šé™¤
            del grid_df
        
        # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®æ¤œå‡º
        memory_increase = memory_readings[-1] - initial_memory
        max_memory = max(memory_readings)
        avg_processing_time = sum(processing_times) / len(processing_times)
        
        print(f"ğŸ“Š ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆçµæœ:")
        print(f"  - æœ€çµ‚ãƒ¡ãƒ¢ãƒªå¢—åŠ : {memory_increase:.2f} MB")
        print(f"  - æœ€å¤§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {max_memory:.2f} MB")
        print(f"  - å¹³å‡å‡¦ç†æ™‚é–“: {avg_processing_time:.3f}ç§’")
        
        # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®è©•ä¾¡
        memory_leak_ok = memory_increase < 20  # 20MBä»¥ä¸‹ãªã‚‰è¨±å®¹
        performance_stable = max(processing_times) / min(processing_times) < 2.0  # 2å€ä»¥ä¸‹ãªã‚‰å®‰å®š
        
        if memory_leak_ok:
            print("âœ… ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        else:
            print("âš ï¸ è­¦å‘Š: ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        if performance_stable:
            print("âœ… å‡¦ç†æ™‚é–“ã¯å®‰å®šã—ã¦ã„ã¾ã™")
        else:
            print("âš ï¸ è­¦å‘Š: å‡¦ç†æ™‚é–“ãŒä¸å®‰å®šã§ã™")
        
        return memory_leak_ok and performance_stable
        
    except Exception as e:
        print(f"âŒ ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print(f"ğŸ“… å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ’» ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±:")
    print(f"  - CPUæ•°: {psutil.cpu_count()}")
    print(f"  - ç·ãƒ¡ãƒ¢ãƒª: {psutil.virtual_memory().total / 1024 / 1024 / 1024:.1f} GB")
    print(f"  - åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª: {psutil.virtual_memory().available / 1024 / 1024 / 1024:.1f} GB")
    print("=" * 50)
    
    test_results = []
    
    # å„ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
    tests = [
        ("å¤§é‡ãƒ‡ãƒ¼ã‚¿ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", test_large_data_performance),
        ("æœ€é©åŒ–æ©Ÿèƒ½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", test_optimization_performance),
        ("ä¸¦è¡Œå‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", test_concurrent_operations),
    ]
    
    for test_name, test_func in tests:
        print(f"\nğŸ” {test_name}ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        try:
            result = test_func()
            test_results.append((test_name, result))
            if result:
                print(f"âœ… {test_name}ãƒ†ã‚¹ãƒˆ: æˆåŠŸ")
            else:
                print(f"âŒ {test_name}ãƒ†ã‚¹ãƒˆ: å¤±æ•—")
        except Exception as e:
            print(f"âŒ {test_name}ãƒ†ã‚¹ãƒˆ: ä¾‹å¤–ç™ºç”Ÿ - {str(e)}")
            test_results.append((test_name, False))
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 50)
    print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 50)
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… æˆåŠŸ" if result else "âŒ å¤±æ•—"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nğŸ¯ ç·åˆçµæœ: {passed}/{total} ãƒ†ã‚¹ãƒˆæˆåŠŸ")
    
    if passed == total:
        print("ğŸ‰ å…¨ã¦ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        return True
    else:
        print("âš ï¸ ä¸€éƒ¨ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)